#!/usr/bin/env bash

#
# NOTE: this is almost directly taken from .github/workflows/CloudTesting.yml
# what it's missing is the write preparation, which _can_ be done, but needs to be run
# like:
#   scripts/run_databricks_env make release write_tests_prepare write_tests_run write_tests_cleanup
#

#export DATABRICKS_TOKEN='op://testing-rw/databricks_free/token'
#export DATABRICKS_ENDPOINT='op://testing-rw/databricks_free/endpoint'
#export DATABRICKS_REGION='op://testing-rw/databricks_free/aws_region'
# NOTE: _env below gets the 3 vars above directly
eval $(op read op://testing-rw/databricks_free/_env | op inject)

# Create Databricks config
cat >~/.databrickscfg <<EOF
[DEFAULT]
host = $DATABRICKS_ENDPOINT
token = $DATABRICKS_TOKEN
EOF

schema_rand="$(uuidgen | tr '[:upper:]' '[:lower:]' | tr '-' '_' | cut -b1-6)"
export DATABRICKS_WRITE_TEST_CATALOG=duckdb_write_testing
export DATABRICKS_WRITE_TEST_SCHEMA="test_schema_$schema_rand"

exec "$@"
